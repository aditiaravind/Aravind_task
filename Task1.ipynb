{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Hand Gesture Classification using EMG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.subplots import make_subplots\n",
    "import h5py \n",
    "\n",
    "py.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, GRU, Dropout, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (ModelCheckpoint,\n",
    "                             TensorBoard, ReduceLROnPlateau,\n",
    "                             CSVLogger, EarlyStopping)\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = r\"C:\\Users\\Aditi\\Google Drive\\Internship\\Insai\\EMG_data_for_gestures-master\\EMG_data_for_gestures-master\\01\\1_raw_data_13-12_22.03.16.txt\"\n",
    "file2 = r\"C:\\Users\\Aditi\\Google Drive\\Internship\\Insai\\EMG_data_for_gestures-master\\EMG_data_for_gestures-master\\01\\2_raw_data_13-13_22.03.16.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file2, delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot EMG Data\n",
    "layout = go.Layout(title = 'Person 1 Data (All Channels)')\n",
    "\n",
    "data = []\n",
    "for i in range(1,9):\n",
    "    trace = go.Scatter(\n",
    "        x = df['time'],\n",
    "        y = df['channel'+str(i)],\n",
    "        name = 'channel'+str(i),\n",
    "        mode = 'lines'\n",
    "    )\n",
    "    data.append(trace)\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "py.offline.iplot(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Note\n",
    "Plotly, in my opinion, is preferable over matplotlib for a few reasons\n",
    "<br> Most importantly, it has dynamic zoom and pan. This feature is essentially perfect when working with time-series data. <br>\n",
    "It is a little more complex to code, but worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1\n",
    "                    , row_heights=[0.7, 0.3],\n",
    "                     subplot_titles=(\"Signal Channels\", \"Gesture Classes\"))\n",
    "fig.update_layout(title = \"Subject 1, Trial 2, EMG Data\")                   \n",
    "\n",
    "for i in range(1,9):\n",
    "    trace = go.Scatter(\n",
    "        x = df['time'],\n",
    "        y = df['channel'+str(i)],\n",
    "        name = 'Channel '+str(i),\n",
    "        mode = 'lines'\n",
    "    )\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = df['time'],\n",
    "        y = df['class'], name='Gesture Class'),\n",
    "              row=2, col=1)\n",
    "\n",
    "#comment this line incase full graph with Legend is not visible \n",
    "fig.update_layout(autosize=False,width = 1100, height=700)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(file1, delimiter=\"\\t\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=2, cols=1\n",
    "                    , row_heights=[0.7, 0.3],\n",
    "                     subplot_titles=(\"Signal Channels\", \"Gesture Classes\"))\n",
    "fig.update_layout(title = \"Subject 1, Trial 1, EMG Data\")                   \n",
    "\n",
    "for i in range(1,9):\n",
    "    trace = go.Scatter(\n",
    "        x = df1['time'],\n",
    "        y = df1['channel'+str(i)],\n",
    "        name = 'Channel '+str(i),\n",
    "        mode = 'lines'\n",
    "    )\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Scatter(x = df1['time'],\n",
    "        y = df1['class'], name='Gesture Class'),\n",
    "              row=2, col=1)\n",
    "\n",
    "#comment this line incase full graph with Legend is not visible \n",
    "fig.update_layout(autosize=False,width = 1100, height=700)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the descriptions, we can see that all the channels have a similar range and scale. \n",
    "- This means that Normalization and Scaling is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = df1.pivot_table(index=['class'], aggfunc='size')\n",
    "print(class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = df.pivot_table(index=['class'], aggfunc='size')\n",
    "print(class_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(class_dist[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The imbalance in the data is mostly due to the \"Unmarked Data\" from Class 0\n",
    "- Rest of the data seems to be more or less of equal ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using each channel separately as a feature\n",
    "Adding both trials together since they are from the same subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df, df1])\n",
    "y = df_total['class'].to_numpy()\n",
    "X = df_total.drop(['time','class'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X, axis=0) #not necessary, but is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class = 'ovr'\n",
    "# multi_class = 'multinomial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear',  random_state=42,\n",
    "                             multi_class=multi_class).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tried multiple combinations of parameters <br>\n",
    "- Final accuracy does not change. <br>\n",
    "- Logistic Regression thus gives a max accuracy of about 65% <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "This could be due to a number of reasons:\n",
    "- It is likely that the imbalance in the data has led to this\n",
    "- Additionally, with a logistic classifier and time series data, a high accuracy cannot be expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2\n",
    "Dropping the class 0 entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_total[df_total['class']!=0]\n",
    "y = X['class'].to_numpy()\n",
    "X = X.drop(['time', 'class'], axis=1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear', random_state=42,\n",
    "                             multi_class=multi_class).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "- By the vast difference in the accuracies, it can be inferred that the previous classifier only did well because it mostly classified the inputs at Class 0.\n",
    "- Due to the large difference in distributions, the classifier gets best accuracy by simply calling all inputs as Class 0\n",
    "- This can be rectified by assigning weights to the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear', max_iter=100, random_state=42,\n",
    "                             multi_class=multi_class, penalty='l1', class_weight='balanced').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b> The accuracy still does not seem to move higher than 65%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Approach : The data is a time-series; Use chunks of the data as input\n",
    "\n",
    "- For example, the class 1 has about 1500 of sequential data at 2 different times\n",
    "- So, take sections of the data from a moving window of size 150 like: \n",
    "        1-150, 2-151, 3-152 and so on.\n",
    "- For each of these sequences, the output class is 1\n",
    "- This will help increase the amount fo input data, while also exploting the time-series nature of the dataset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input shape will come to be : \n",
    "<br> <b> n_samples x n_\"features\"(150) x n_channels(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Additionally, the Recurrent Neural Network is one of the best approaches for time-series' predictions.\n",
    "- While CNNs may be better overall, the noisiness of the EMG data might yield poorer results.\n",
    "- Treating them as sequence sections that the Gated recurrent network can pick up is a good approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_seq(data, seq_length):\n",
    "    n = len(data)\n",
    "    out = []\n",
    "    for i in range(n-seq_length+1):\n",
    "        seq = data[i:i+seq_length]\n",
    "        out.append(seq)\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((1,8,150))\n",
    "y = []\n",
    "for Class in range(max(df_total['class']) +1):\n",
    "    df_class = df_total[df_total['class']==Class].drop(['time', 'class'], axis=1)\n",
    "    class_seq = []\n",
    "    for channel in df_class.columns:\n",
    "        chn = df_class[channel]\n",
    "        seq = data_to_seq(chn, 150)\n",
    "        class_seq.append(seq)\n",
    "    class_seq = np.array(class_seq)\n",
    "    print(class_seq.shape)\n",
    "    y = y + [Class]*class_seq.shape[1]\n",
    "    X = np.concatenate([X,class_seq.reshape(class_seq.shape[1], 8, 150)])\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "# X = np.vstack(X.reshape(X.shape[0],7162,8,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing Data to a file and saving, since the above cells take a lot of time to run\n",
    "(The Data file will be uploaded on GDrive and the link has been given in the readme file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using h5py\n",
    "hf = h5py.File('Task1_sequences.h5', 'w')\n",
    "hf.create_dataset('X', data=b)\n",
    "hf.create_dataset('y', data=y)\n",
    "hf.create_dataset('info', data='Sequences of sliced data from the original dataset, with slices of length 150 each along with the corresponding class values')\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the files like this:\n",
    "hf = h5py.File('Task1_sequences.h5', 'r')\n",
    "X = hf['X']\n",
    "y = hf['y']\n",
    "# hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model Architecture is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In = Input(shape=(8,150), dtype=np.float32, name='signal')\n",
    "\n",
    "x = In\n",
    "gru1 = GRU(64, return_sequences=True, dropout=0.2, name = 'GRU-1')\n",
    "x = Bidirectional(gru1, name='BiRNN-1')(x)\n",
    "\n",
    "gru2 = GRU(128, return_sequences=False, dropout=0.2, name = 'GRU-2')\n",
    "x = Bidirectional(gru2, name='BiRNN-2')(x)\n",
    "\n",
    "x = Dense(64, name='Dense-1', activation='relu')(x)\n",
    "x = Dense(16, name='Dense-2', activation='relu')(x)\n",
    "\n",
    "diagn = Dense(7, activation='sigmoid', name = 'Dense-3')(x)\n",
    "model = Model(In, diagn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = 'binary_crossentropy'\n",
    "lr = 0.001\n",
    "batch_size = 64\n",
    "opt = Adam(lr)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks = [ReduceLROnPlateau(monitor='val_loss',\n",
    "#                                factor=0.1,\n",
    "#                                patience=7,\n",
    "#                                min_lr=lr / 10),\n",
    "#              EarlyStopping(patience=9, min_delta=0.00001)]\n",
    "\n",
    "callbacks = [TensorBoard(log_dir='./logs', batch_size=batch_size, write_graph=False),\n",
    "              CSVLogger('training.log', append=False)]  # Change append to true if continuing training\n",
    "# Save the BEST and LAST model\n",
    "callbacks += [ModelCheckpoint('./backup_model_last.hdf5'),\n",
    "              ModelCheckpoint('./backup_model_best.hdf5', save_best_only=True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(np.argmax(y[:], axis=1)),np.argmax(y[:], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=100,\n",
    "                    validation_split=0.05,\n",
    "                    shuffle=True,\n",
    "                    callbacks=callbacks,\n",
    "                    verbose=1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./final_model.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we have a RNN model with very good accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
